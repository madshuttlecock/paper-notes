## Autonomous helicopter flight via reinforcement learning

Link: https://bit.ly/2Yy53LH

## Проблемы

1. Сложные, нелинейные зависимости позиции вертолета от управления
2. Асимметрия в управлении

Вертолет летает благодаря вертящимся винтам, поэтому на него действует множество различных сил, 
нет симметрии, управление сложно.

## Задача

Научить вертолет висеть в воздухе и выполнять маневры, используя RL и искусственную модель среды.

Агент должен научиться выполнять подходящие действия каждую 1/500 секунды.

## Решение

## Создание модели среды

1. Состояние: координаты, скорость, угловая скорость. Также был сделан переход в систему координат относительно вертолета,
так как управление зависит не от положения вертолета в пространстве, а от относительных скоростей и.т.п.

2. Данные о среде собраны во время полета пилота-человека.

3. Создается модель, предсказывающая s(t+1) - s(t) по s(t), a(t)

Авторы использовали locally weighted linear regression. К модели также добавлялся шум 
из нормального распределения, параметры которого были оценены наряду с параметрами модели. Таким образом, была создана 
стохастическая виртуальная среда.

## Обучение

I. Для обучения агента используется PEGASUS algorithm:

Стандартный метод Монте-Карло + 
авторы избавляются от рандома путем фиксирования заранее всех рандомных чисел, 
нужных для генерации стохастической среды.

Далее авторы максимизируют функцию среднего реворда по играм стандартными методами (градиентный спуск/ случайный поиск)

В качестве политики используется однослойная нейронная сеть (не все ребра проведены - учет физических особенностей). 
Фактически, это линейная регрессия с добавленными нелинейностями tanh.

II. Rewards

1. Полет на месте: минус взвешенная квадратичная функция отклонения от желаемых координат + регуляризация по скоростям, 
чтобы сделать полет более плавным.

2. В случае выполнения маневров в качестве желаемых координат используется проекция на желаемую траекторию, 
добавляется reward за продвижение по траектории (в виде некоего потенциала). 

Обучение может производиться для произвольной тректории, но для каждой из них придется обучать отдельную политику.

С помощью описанных выше методов удалось обучить вертолет не только стабильно зависать в воздухе, но и выполнять сложные 
маневры с RC helicopter competition, организованного The Academy of Model Aeronautics (AMA).


